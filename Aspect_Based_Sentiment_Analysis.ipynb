{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVBNVXqO4gumuMcfT1sCJB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashish-Sinha07/Ashish-Sinha-programmer-202070/blob/main/Aspect_Based_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "IQLdEoWKREjb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90cda00e-4960-4545-f76b-414e5da5e04e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wsd5IGzDRkOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***`Aspect-Based Sentiment Analysis`***"
      ],
      "metadata": {
        "id": "MdriczqrStcm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Loading JSON Data**"
      ],
      "metadata": {
        "id": "UyG_3XRORkbr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-R24_xRYQe2A"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Function to read JSON files\n",
        "def read_json_file(file_path):\n",
        "    data = []\n",
        "    with open(file_path, 'r') as f:\n",
        "        for line in f:\n",
        "            data.append(json.loads(line))\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# Load business and review data\n",
        "business_df = read_json_file('/content/drive/MyDrive/CSV/dataset/dataset/yelp_academic_dataset_business.json')\n",
        "review_df = read_json_file('/content/drive/MyDrive/CSV/dataset/dataset/yelp_academic_dataset_review.json')\n",
        "user_df = read_json_file('/content/drive/MyDrive/CSV/dataset/dataset/yelp_academic_dataset_user.json')\n",
        "tip_df = read_json_file('/content/drive/MyDrive/CSV/dataset/dataset/yelp_academic_dataset_tip.json')\n",
        "checkin_df = read_json_file('/content/drive/MyDrive/CSV/dataset/dataset/yelp_academic_dataset_checkin.json')\n",
        "\n",
        "# Display structure of the data\n",
        "print(business_df.head())\n",
        "print(review_df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Preprocessing the Data**"
      ],
      "metadata": {
        "id": "6hsWTJt6RzlI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Function for cleaning text\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^A-Za-z\\s]', '', text)  # Remove special characters\n",
        "    text = text.lower()  # Convert text to lowercase\n",
        "    tokens = word_tokenize(text)  # Tokenize text\n",
        "    tokens = [word for word in tokens if word not in stopwords.words('english')]  # Remove stopwords\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Apply cleaning to review text\n",
        "review_df['clean_text'] = review_df['text'].apply(clean_text)\n",
        "print(review_df['clean_text'].head())\n"
      ],
      "metadata": {
        "id": "nbFcmMH3Qi_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Aspect Extraction**"
      ],
      "metadata": {
        "id": "7n-IchXQR6Pt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define aspect keywords for matching\n",
        "aspect_keywords = {\n",
        "    'food_quality': ['food', 'taste', 'flavor', 'dish', 'meal'],\n",
        "    'service': ['service', 'waiter', 'staff', 'attitude', 'helpful'],\n",
        "    'ambiance': ['ambiance', 'atmosphere', 'decor', 'environment'],\n",
        "    'pricing': ['price', 'cost', 'value', 'expensive', 'cheap'],\n",
        "    'cleanliness': ['clean', 'hygiene', 'tidy', 'dirty', 'sanitary']\n",
        "}\n",
        "\n",
        "# Function to extract aspects based on keywords\n",
        "def extract_aspects(text, aspect_keywords):\n",
        "    extracted_aspects = []\n",
        "    for aspect, keywords in aspect_keywords.items():\n",
        "        for word in keywords:\n",
        "            if word in text:\n",
        "                extracted_aspects.append(aspect)\n",
        "                break\n",
        "    return extracted_aspects\n",
        "\n",
        "# Apply aspect extraction\n",
        "review_df['aspects'] = review_df['clean_text'].apply(lambda x: extract_aspects(x, aspect_keywords))\n",
        "print(review_df[['text', 'aspects']].head())\n"
      ],
      "metadata": {
        "id": "dA8AjFxZQls0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Sentiment Classification**"
      ],
      "metadata": {
        "id": "HpN51QxgR_Nw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "# Initialize VADER sentiment analyzer\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Function for sentiment classification\n",
        "def classify_sentiment(text):\n",
        "    sentiment_score = sia.polarity_scores(text)['compound']\n",
        "    if sentiment_score >= 0.05:\n",
        "        return 'positive'\n",
        "    elif sentiment_score <= -0.05:\n",
        "        return 'negative'\n",
        "    else:\n",
        "        return 'neutral'\n",
        "\n",
        "# Apply sentiment classification to review text\n",
        "review_df['sentiment'] = review_df['clean_text'].apply(classify_sentiment)\n",
        "print(review_df[['text', 'sentiment']].head())\n"
      ],
      "metadata": {
        "id": "RWTNGoU0Qnwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Combining Aspect and Sentiment**"
      ],
      "metadata": {
        "id": "atBYq3QeSJoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to assign sentiment to each extracted aspect\n",
        "def assign_sentiment_to_aspects(aspects, sentiment):\n",
        "    aspect_sentiments = {}\n",
        "    for aspect in aspects:\n",
        "        aspect_sentiments[aspect] = sentiment\n",
        "    return aspect_sentiments\n",
        "\n",
        "# Apply aspect sentiment classification\n",
        "review_df['aspect_sentiments'] = review_df.apply(lambda row: assign_sentiment_to_aspects(row['aspects'], row['sentiment']), axis=1)\n",
        "print(review_df[['text', 'aspect_sentiments']].head())\n"
      ],
      "metadata": {
        "id": "OksWpHShQpRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Generate Business Insights**"
      ],
      "metadata": {
        "id": "jmPf03j4SQXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by business to get overall sentiment distribution\n",
        "business_sentiment = review_df.explode('aspects').groupby(['business_id', 'aspects']).agg({\n",
        "    'sentiment': lambda x: x.value_counts().index[0]\n",
        "}).reset_index()\n",
        "\n",
        "# Merge with business data to add business details\n",
        "business_sentiment = pd.merge(business_sentiment, business_df[['business_id', 'name', 'categories']], on='business_id', how='left')\n",
        "print(business_sentiment.head())\n",
        "\n",
        "# Generate business insights\n",
        "def generate_insights(df):\n",
        "    insights = {}\n",
        "    for business in df['business_id'].unique():\n",
        "        business_reviews = df[df['business_id'] == business]\n",
        "        insights[business] = {\n",
        "            'name': business_reviews['name'].iloc[0],\n",
        "            'categories': business_reviews['categories'].iloc[0],\n",
        "            'aspects': business_reviews.groupby('aspects')['sentiment'].value_counts().to_dict()\n",
        "        }\n",
        "    return insights\n",
        "\n",
        "# Generate insights for all businesses\n",
        "business_insights = generate_insights(business_sentiment)\n",
        "print(business_insights)\n"
      ],
      "metadata": {
        "id": "CK0ZNh0XQqnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. Visualization**"
      ],
      "metadata": {
        "id": "zgyH4-qMSS6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Example: Sentiment distribution for a specific business and aspect\n",
        "def plot_sentiment_distribution(business_id, aspect, df):\n",
        "    business_reviews = df[(df['business_id'] == business_id) & (df['aspects'] == aspect)]\n",
        "    sns.countplot(x='sentiment', data=business_reviews)\n",
        "    plt.title(f'Sentiment Distribution for {aspect} - Business {business_id}')\n",
        "    plt.show()\n",
        "\n",
        "# Example: Plot for a specific business and aspect\n",
        "plot_sentiment_distribution('tnhfDv5Il8EaGSXZGiuQGg', 'food_quality', review_df)\n"
      ],
      "metadata": {
        "id": "jtWDpO2IQuAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ILlq5Jx_X_2U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}